{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import Adam\n",
    "from lib.config.config_dna import get_config\n",
    "import time\n",
    "import tqdm\n",
    "import tabix\n",
    "import pyBigWig\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from lib.models.ddsm import *\n",
    "from selene_sdk.utils import NonStrandSpecific\n",
    "from selene_sdk.targets import Target\n",
    "from lib.sei.sei import Sei\n",
    "from lib.datasets.datasets import TSSDatasetS, prepare_dna_valid_dataset\n",
    "import os\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from lib.models.networks import DNAScoreNet\n",
    "from lib.training.training import Trainer\n",
    "from lib.sampling.sampling import Euler_Maruyama_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resume = False\n",
    "if not train_resume:\n",
    "    config = get_config()\n",
    "    bookkeeping.save_config(config, config.save_location)\n",
    "\n",
    "else:\n",
    "    path = 'path/to/saved/models'\n",
    "    date = 'date'\n",
    "    config_name = 'config_name.yaml'\n",
    "    config_path = os.path.join(path, date, config_name)\n",
    "\n",
    "    configfg = bookkeeping.load_config(config_path)\n",
    "\n",
    "sei_features = pd.read_csv(config.seifeatures_file, sep='|', header=None)\n",
    "sei = nn.DataParallel(NonStrandSpecific(Sei(4096, 21907)))\n",
    "sei.load_state_dict(torch.load(config.sei.seimodel_file, map_location='cpu')['state_dict'])\n",
    "#sei.cuda()\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "# hiermit importance sampling und mit rand_offset=100 in train()\n",
    "train_set = TSSDatasetS(config, n_tsses=40000, rand_offset=10)\n",
    "data_loader = DataLoader(train_set, batch_size=config.data.batch_size, shuffle=True, num_workers=config.data.num_workers)\n",
    "\n",
    "trainer = Trainer(config)\n",
    "valid_datasets, valid_seqs = prepare_dna_valid_dataset(config, sei, sei_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DNAScoreNet()\n",
    "optimizer = Adam(model.parameters(), lr=config.optimizer.lr)\n",
    "n_iter = 0\n",
    "state = {\"model\": model, \"optimizer\": optimizer, \"n_iter\": 0}\n",
    "\n",
    "if train_resume:\n",
    "    checkpoint_path = 'path/to/saved/models'\n",
    "    model_name = 'model_name.pt'\n",
    "    checkpoint_path = os.path.join(path, date, model_name)\n",
    "    state = bookkeeping.load_state(state, checkpoint_path)\n",
    "    config.training.n_iters = 36000\n",
    "    config.sampler.sample_freq = 36000\n",
    "    config.saving.checkpoint_freq = 1000\n",
    "    \n",
    "sampler = Euler_Maruyama_sampler\n",
    "\n",
    "\n",
    "trainer.train(state, sampler, sei, sei_features, data_loader, valid_datasets, valid_seqs)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
